{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 학습 데이터 분리 하지 않으면 100점만 나온다. (새로운 데이터를 잘 맞추기 위함)\n",
    "2. randomstate는 과제 제출시 동일한 결과를 위해 없다면 xtrain과 xtest가 바뀜,shuffle\n",
    "3. 예측성은 테스트데이터에 대한 성능\n",
    "4. predict는 테스트 데이터 세트로(검증데이터와 테스트 데이터가 다르다.)\n",
    "5. 학습,테스트 데이터로 성능 차이가 크다 (kfold교차검증시 증명,평균을 구해서 성능출력)\n",
    "6. Stratified K-fold 교차검증: k-fold의 부족함을 채우기위함 분류에서만 해당됨, 데이터가 골고루 섞이도록 맞춰줌 분류할때는 꼭 써야함\n",
    "7. 교차검증은 cross_val_score()가 간단함\n",
    "8. 교차검증별 정확도가 비슷해야 평균 검증 정확도가 의미를 가짐\n",
    "9. 가장중요 GridSearchCV(필수)로 이미 학습된 estimator변환\n",
    "10. 하이퍼파라미터에 따라 같은 알고리즘이 다른 결과를 낸다.\n",
    "\n",
    "girdsearchcv가 하는일\n",
    "데이터 분류 -> 최적의 파라미터 탐색 -> #학습 ->최적의값을 estimator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) train_test_split에서 정확한 알고리즘 성능평가를 위해서는 random_state를 사용하지 않는\n",
    "것이 좋다. 그런데, random_state를 사용하는 경우는 언제인가?\n",
    "\n",
    "- 동일한 알고리즘에서 동일한 결과를 얻기위함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) train_test_split 함수로 iris 데이터를 분리하려고 한다. test_size =0.4일 경우\n",
    "학습데이터와 테스트데이터는 각각 몇 개인가?\n",
    "\n",
    "- 학습데이터 n/0.6,테스트데이터 n/0.4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) train_test_split 함수는 random shuffle을 통해 학습데이터와 테스트데이터를 나누기\n",
    "때문에 알고리즘 성능을 괜찮게 측정한다고 볼 수 있는데도, 교차 검증을 한다. 그 이유?\n",
    "\n",
    " - 학습데이터와 테스트 데이터에따라 같은 알고리즘이라도 다른결과가 나올수 있기 때문이다.\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) 일반적인 K 폴드 교차검증 대신 Stratified K-fold 교차검증을 하는 이유는?\n",
    "- k-fold에서 데이터셋을 나눌때 골고루 나눠지지 않는 문제점이 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) 회귀분석에서 Stratified K-fold 교차검증을 사용할 수 없는 이유는?\n",
    "\n",
    "회귀분석에서는 같은 label을 가진 데이터가 많지않아 골고루 섞는게 거의 불가능하다.\n",
    "분류는 같은 label을 가진 데이터가 많다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) cross_val_score 함수는 K-폴드 교차검증이나 Stratified K-폴드 교차검증과 비교할 때, 어떤 점이 편리하여 사용하는가?\n",
    "\n",
    "\n",
    "(1) 폴드 세트 설정\n",
    "\n",
    "(2) for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스 추출\n",
    "\n",
    "(3) 반복적으로 학습과 예측을 수행하고 예측 성능 구하여 저장을 한번해 할 수 있다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) 모델 파라미터는 무엇이고, 하이퍼 파라미터는 무엇인가?\n",
    "\n",
    "- 모델파라미터는 학습되는것 이고, 하이퍼 파라미터는 사용자가 입력하는 값이라 학습이 되는 값이 아닌것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) DT의 하이퍼파라미터 중 min_sample_split과 max_depth에 대해 설명하시오.\n",
    "- min_sample_split: 노드 분할을 위한 최소한의 샘플 데이터 수\n",
    "- max_depth: 트리의 최대깊이를 지정함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9) DT에서 (트리의 길이가 짧은) 단순한 모델을 만들기 위해, min_sample_split을 크게 해야\n",
    "하는가? 아님 작게 해야 하는가? max_depth 값은 크게 해야 하는가? 아님 작게 해야\n",
    "하는가?\n",
    "\n",
    "- 트리가 짧은 모델은 만들기 위해서는 min_sample_split은 크게, max_depth 의 값을 작게해야한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10) GridSearchCV 함수에서 cv = 5이고, pram_grid가 다음과 같을 때, 학습은 몇 번\n",
    "수행하는가?\n",
    "param_grid = {‘max_depth’: [2, 3, 4], ‘min_samples_split’: [2, 3, 4]}\n",
    "- 5번수행함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(11-12) cross_val_score와 같은 기능을 하는 my_dt_cross_val_score 함수를 작성하시오. my_dt_cross_val_score 는 결정트리 Classifier를 사용하여 accuracy 리스트를 반환하는 함수로, 입력 파라미터는 X, y, cv 등 3개 뿐이다.\n",
    "\n",
    "#(11) 일반적인 K-폴드 교차검증 결과를 반환하는 함수를 작성하고, p.110 코드를 참고하여 적절히 호출하여 잘 작동됨을 보이시오.\n",
    "def mt_dt_cross_val_score(x,y,cv):\n",
    "    for i in range(cv):\n",
    "        \n",
    "\n",
    "#(12) Stratified K-폴드 교차검증 결과를 반환하는 함수를 작성하고, p.110 코드를 참고하여 적절히 호출하여 잘 작동됨을 보이시오.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터: {'max_depth': 2, 'min_samples_split': 2}\n",
      "최적의 정확도: 0.9333%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>13</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>13</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 4}</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>13</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 4}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 4}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 2}</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 3}</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 4}</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>7</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 3}</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 4}</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>7</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_score  \\\n",
       "0   {'max_depth': 1, 'min_samples_split': 2}         0.691667   \n",
       "1   {'max_depth': 1, 'min_samples_split': 3}         0.691667   \n",
       "2   {'max_depth': 1, 'min_samples_split': 4}         0.691667   \n",
       "3   {'max_depth': 2, 'min_samples_split': 2}         0.933333   \n",
       "4   {'max_depth': 2, 'min_samples_split': 3}         0.933333   \n",
       "5   {'max_depth': 2, 'min_samples_split': 4}         0.933333   \n",
       "6   {'max_depth': 3, 'min_samples_split': 2}         0.933333   \n",
       "7   {'max_depth': 3, 'min_samples_split': 3}         0.933333   \n",
       "8   {'max_depth': 3, 'min_samples_split': 4}         0.933333   \n",
       "9   {'max_depth': 4, 'min_samples_split': 2}         0.900000   \n",
       "10  {'max_depth': 4, 'min_samples_split': 3}         0.900000   \n",
       "11  {'max_depth': 4, 'min_samples_split': 4}         0.908333   \n",
       "12  {'max_depth': 5, 'min_samples_split': 2}         0.900000   \n",
       "13  {'max_depth': 5, 'min_samples_split': 3}         0.900000   \n",
       "14  {'max_depth': 5, 'min_samples_split': 4}         0.908333   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \n",
       "0                13           0.666667           0.666667           0.708333  \n",
       "1                13           0.666667           0.666667           0.708333  \n",
       "2                13           0.666667           0.666667           0.708333  \n",
       "3                 1           0.916667           0.916667           0.958333  \n",
       "4                 1           0.916667           0.916667           0.958333  \n",
       "5                 1           0.916667           0.916667           0.958333  \n",
       "6                 1           0.916667           0.916667           0.958333  \n",
       "7                 1           0.916667           0.916667           0.958333  \n",
       "8                 1           0.916667           0.916667           0.958333  \n",
       "9                 9           0.875000           0.916667           0.958333  \n",
       "10                9           0.875000           0.916667           0.958333  \n",
       "11                7           0.875000           0.916667           0.958333  \n",
       "12                9           0.875000           0.916667           0.958333  \n",
       "13                9           0.875000           0.916667           0.958333  \n",
       "14                7           0.875000           0.916667           0.958333  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(13) 다음은 DT를 이용하여 iris 데이터를 분류하는 모델을 학습하고 테스트하는 코드이다. 교재 p.113-115 코드를 참고하여 코드를 보완하여 완성하시오.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
    " test_size=0.2, random_state=10)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# 각자 'max_depth'와 'min_samples_split()' 범위를 설정하여 딕셔너리 parameters에 저장하시오.\n",
    "parameters = {'max_depth':[1,2,3,4,5], 'min_samples_split':[2,3,4]}\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=5, refit=True)\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "print(\"최적의 파라미터:\",grid_dtree.best_params_)\n",
    "print(\"최적의 정확도: {0:.4f}%\".format(grid_dtree.best_score_))\n",
    "# 나머지 코드를 작성하여 가장 좋은 하이퍼 파라미터를 갖는 모델을 학습하시오. # 가장 좋은 하이퍼 파라미터 값과 테스트데이터 셋에 대한 정확도 값을 출력하시오.\n",
    "score_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "score_df[['params', 'mean_test_score', 'rank_test_score', \\\n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]\n",
    "\n",
    "print(\"최고 정확도가 최적 정확도 보다 높다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
