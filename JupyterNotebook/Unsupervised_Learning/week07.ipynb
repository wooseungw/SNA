{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.array([1,2,6])\n",
    "np.var(n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원핫인코딩을 자주사용함,회귀분석에서 자주사용됨\n",
    "DT는 따로 안해도된다.\n",
    "딥러닝에서는 전처리를 따로 하지않아도 된다.\n",
    "스케일링은 회귀분석에서 중요하다\n",
    "표준화: 데이터집합을 columm별로 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) One-Hot Encoding이 Label Encoding에 비해 우수한 이유는?\n",
    "\n",
    "레이블간 거리가 일정하기 때문에 알고리즘이 오해할 일이 없어진다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 다음 데이터를 표준화로 변환하시오(표준화 하시오)\n",
    "1,2,6\n",
    "\n",
    "평균->표준편차((1/2)((1-3)^2 + (2-3)^2 + (6-3)^2))^1/2 구하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 다음 데이터를 정규화로 변환하시오(정규화 하시오).\n",
    " 1, 2, 6\n",
    "\n",
    " 1-1/5 , 2-1/5, 6-1/5 = 0, 1/5, 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) 표준화 또는 정규화 시, 테스트 데이터 세트를 이용하여 fit하면 안 되는 이유는?\n",
    "\n",
    "fit는 학습단계에서만 하는것"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) 위 코드를 적절히 수정하여 다음 절차를 따르도록 프로그램을 완성하시오.\n",
    "    \n",
    "    ⓵ 먼저 학습 데이터와 테스트 데이터를 분리한다.\n",
    "    ⓶ 학습데이터를 이용하여 전처리한다. 이때, mean_Age, le_Cabin, le_Sex, le_Embarked를 받아 저장한다. \n",
    "    ⓷ DecisionTreeClassifier와 GridSearchCV를 이용해서 학습데이터를 학습한다. \n",
    "    ⓸ 테스트 데이터를 전처리한다. 이때, mean_Age, le_Cabin, le_Sex, le_Embarked를 이용하여 전처리 한다. \n",
    "    ⓹ 테스트 데이터 레이블을 예측하고 성능을 평가한다. # 레이블 인코딩 대신 One-Hot Encoding으로 수정하면 좋으나 힘들 것 같아 각자 맡긴다. 이번 시험에 안 나옴.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'N' 'T']\n",
      "['female' 'male']\n",
      "['C' 'N' 'Q' 'S']\n",
      "GridSearchCV 최적 하이퍼 파라미터 : {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.7992\n",
      "테스트 세트에서의 DecisionTreeClassifier 정확도 : 0.8715\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 데이터 로드\n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived',axis=1)\n",
    "\n",
    "# 1 번\n",
    "# 학습/테스트 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    " test_size=0.2, random_state=11)\n",
    "\n",
    "# 2번\n",
    "mean_Age = titanic_df['Age'].mean()\n",
    "le_Embarked =[0];\n",
    "le_Sex =[0];\n",
    "le_Cabin=[0];\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    \n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행.\n",
    "def format_features(df1,df2):\n",
    "    #cabin slicing\n",
    "    df1['Cabin'] = df1['Cabin'].str[:1]\n",
    "    df2['Cabin'] = df2['Cabin'].str[:1]\n",
    "    \n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        #train data 인코딩\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df1[feature])\n",
    "        #print(le.classes_)\n",
    "        #train_data 인코딩\n",
    "        df1[feature] = le.transform(df1[feature])\n",
    "        #test_data 인코딩\n",
    "        df2[feature] = le.transform(df2[feature])\n",
    "            \n",
    "    return df1 , df2\n",
    "\n",
    "\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df1,df2):\n",
    "    df1 = fillna(df1)\n",
    "    df2 = fillna(df2)\n",
    "    df1 = drop_features(df1)\n",
    "    df2 = drop_features(df2)\n",
    "    df1,df2 = format_features(df1,df2)\n",
    "    return df1,df2\n",
    "\n",
    "\n",
    "\n",
    "# 전처리는 학습데이터와 테스트 데이터를 분리한 다음 시행해야함\n",
    "X_train,X_test = transform_features(X_train,X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 학습\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "parameters = {'max_depth':[2,3,5,10],\n",
    "              'min_samples_split':[2,3,5],\n",
    "              'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf , param_grid=parameters , scoring='accuracy' , cv=5)\n",
    "grid_dclf.fit(X_train , y_train)\n",
    "print('GridSearchCV 최적 하이퍼 파라미터 :',grid_dclf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "# 테스트: 예측, 성능평가\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , dpredictions)\n",
    "print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
