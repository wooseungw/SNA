lll;;l4
print("hi")
install.packages("stringr")
## 1.1 package 설치
library()
## 1.1.1 jdk 설치
install.packages("rJava")
install.packages("multilinguer")
library(rJava)
library(multilinguer)
install_jdk()
## 1.1.2 KoNLP 설치(github이용)
install.packages("remotes")
install.packages("remotes")
remotes::install_github('haven-jeon/KoNLP',
upgrade = "never",
INSTALL_opts=c("--no-multiarch"))
## 1.1.3 KoNOP 로드
library(KoNLP)
## 1.1.2 KoNLP 설치(github이용)
install.packages("remotes")
install.packages("remotes")
remotes::install_github('haven-jeon/KoNLP',
upgrade = "never",
INSTALL_opts=c("--no-multiarch"))
remotes::install_github('haven-jeon/KoNLP',
upgrade = "never",
INSTALL_opts=c("--no-multiarch"),
force = TRUE)
## 1.1.3 KoNOP 로드
library(KoNLP)
library(rJava)
library(multilinguer)
## 1.1.2 KoNLP 설치(github이용)
install.packages("remotes")
remotes::install_github('haven-jeon/KoNLP',
upgrade = "never",
INSTALL_opts=c("--no-multiarch"))
install.packages("remotes")
install.packages("remotes")
## 1.1.3 KoNOP 로드
library(KoNLP)
library(rJava)
library(multilinguer)
## 1.1.3 KoNOP 로드
library(KoNLP)
useNIADic() # 단어사전 사용 -
INSTALL_opts=c("--no-multiarch"))
useSejongDic()
extractNoun("나는 학생이며 오늘도 공부를 합니다.")
MorphAnalyzer("나는 강남대학교 학생이며 오늘도 공부를 합니다.")
library(rJava)
library(multilinguer)
## 1.1.3 KoNOP 로드
library(KoNLP)
useNIADic() # 단어사전 사용 -
useSejongDic()
extractNoun("나는 학생이며 오늘도 공부를 합니다.")
MorphAnalyzer("나는 강남대학교 학생이며 오늘도 공부를 합니다.")
# Neural Information Processing Systems	309	503
# 2.	International Conference on Learning Representations	303	563
# 3.	International Conference on Machine Learning	254	463
# 4.	AAAI Conference on Artificial Intelligence	212	344
# 5.	Expert Systems with Applications	148	221
setwd("C:/Workspace/SNA/NLP")
getwd()
library(httr)
library(rvest)
library(dplyr)
library(XML)
# 라이브러리 로드
library(dplyr)
# 각 페이지의 데이터 프레임을 저장할 리스트 초기화
all_pages_data <- list()
max_page = 980
i = 1
for (i in 1:99){
#html <- read_html(paste0("https://scholar.google.co.kr/scholar?start=",(i-1)*10,"&q=source:Neural+source:Information+source:Processing+source:Systems&hl=ko&as_sdt=0,5&as_ylo=",years))
if((i %% 10)==0)
print(i)
html <- read_html(paste0("https://scholar.google.co.kr/scholar?start=",(i-1)*10,"&hl=ko&as_sdt=2005&sciodt=0,5&cites=9281510746729853742&scipsc="))
title <- html_nodes(html, "#gs_res_ccl_mid .gs_rt") %>%
html_text()
title
title <- gsub("\\[PDF]","",title)
title <- gsub("\\[html]","",title)
title <- gsub("\\[HTML]","",title)
title
texts <- html_nodes(html, "#gs_res_ccl_mid .gs_a") %>%
html_text()
texts
authors <- gsub("¡¦","",texts)
authors
# 학술지 정보 추출
journal_names <- sub(".*- (.+), [0-9]{4} -.*", "\\1", texts)
# 출판연도 추출
publication_years <- sub(".*([0-9]{4}).*", "\\1", texts)
#authors
page_data <- data.frame(
Title = title,
Authors = authors,
Journal = journal_names,
Year = publication_years
)
# 리스트에 추가
all_pages_data[[i]] <- page_data
Sys.sleep(10)
}
# 모든 페이지의 데이터를 하나의 데이터 프레임으로 합치기
final_data <- bind_rows(all_pages_data)
# 데이터 프레임을 CSV 파일로 저장
write.csv(final_data, "resnet.csv", row.names = FALSE)
