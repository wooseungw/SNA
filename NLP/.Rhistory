lll;;l4
print("hi")
install.packages("stringr")
## 1.1 package 설치
library()
## 1.1.1 jdk 설치
install.packages("rJava")
install.packages("multilinguer")
library(rJava)
library(multilinguer)
install_jdk()
## 1.1.2 KoNLP 설치(github이용)
install.packages("remotes")
install.packages("remotes")
remotes::install_github('haven-jeon/KoNLP',
upgrade = "never",
INSTALL_opts=c("--no-multiarch"))
## 1.1.3 KoNOP 로드
library(KoNLP)
## 1.1.2 KoNLP 설치(github이용)
install.packages("remotes")
install.packages("remotes")
remotes::install_github('haven-jeon/KoNLP',
upgrade = "never",
INSTALL_opts=c("--no-multiarch"))
remotes::install_github('haven-jeon/KoNLP',
upgrade = "never",
INSTALL_opts=c("--no-multiarch"),
force = TRUE)
## 1.1.3 KoNOP 로드
library(KoNLP)
library(rJava)
library(multilinguer)
## 1.1.2 KoNLP 설치(github이용)
install.packages("remotes")
remotes::install_github('haven-jeon/KoNLP',
upgrade = "never",
INSTALL_opts=c("--no-multiarch"))
install.packages("remotes")
install.packages("remotes")
## 1.1.3 KoNOP 로드
library(KoNLP)
library(rJava)
library(multilinguer)
## 1.1.3 KoNOP 로드
library(KoNLP)
useNIADic() # 단어사전 사용 -
INSTALL_opts=c("--no-multiarch"))
useSejongDic()
extractNoun("나는 학생이며 오늘도 공부를 합니다.")
MorphAnalyzer("나는 강남대학교 학생이며 오늘도 공부를 합니다.")
library(rJava)
library(multilinguer)
## 1.1.3 KoNOP 로드
library(KoNLP)
useNIADic() # 단어사전 사용 -
useSejongDic()
extractNoun("나는 학생이며 오늘도 공부를 합니다.")
MorphAnalyzer("나는 강남대학교 학생이며 오늘도 공부를 합니다.")
setwd("C:/Workspace/SNA/NLP")
getwd()
df <- read.csv('C:/Workspace/SNA/NLP/prerpeoceed_attetion.csv')
# 필요한 라이브러리 로드
#install.packages('tm')
#install.packages('wordcloud')
#install.packages('topicmodels')
#install.packages('LDAvis')
#library(LDAvis)
library(wordcloud)
library(tm)
library(topicmodels)
library(RColorBrewer)
library(ggplot2)
library(dplyr)
library(tidyr)
library(tibble)
# 데이터 프레임에서 제목 컬럼 추출
titles <- df$Title
# 텍스트 전처리
corpus <- Corpus(VectorSource(titles))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("english"), "htmlhtml","attention","learning","transformer","transformers","survey","review","models","model"))
corpus <- tm_map(corpus, stripWhitespace)
# 단어 빈도 분석
dtm <- TermDocumentMatrix(corpus)
m <- as.matrix(dtm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
word_freqs <- data.frame(word = names(word_freqs), freq = word_freqs)
# 색상 팔레트 생성
palette <- c(brewer.pal(8, "Dark2"), brewer.pal(4, "Set3"))
# 가장 많이 사용된 단어 시각화
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 3, max.words = 300, scale = c(3.9, 0.9), random.order = FALSE,colors = palette)
png("wordcloud.png", width = 800, height = 600)
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 3, max.words = 300, scale = c(3.9, 0.9), random.order = FALSE,colors = palette)
dev.off()
